üìå README ‚Äì Pipeline de Processamento de Projetos + Dashboard Power BI (Indicadores GEP ‚Äì HU-UFPI)
üè• Sobre o Projeto

--link de vizualia√ß√£o do overleaf : https://www.overleaf.com/read/drsyczzjpkbx#5538b2

Grupo :

Ygor Jivago 
Vinicius Azevedo
Augusto C√©sar
Mateus Faria
Talyson Machado
Th√©o Alencar da Silva

Este projeto foi desenvolvido como parte de um trabalho de extens√£o relacionado ao Hospital Universit√°rio da Universidade Federal do Piau√≠ (HU-UFPI).
Ele possui duas partes integradas, que juntas criam um fluxo completo de an√°lise de dados dos projetos do GEP (Gest√£o Estrat√©gica de Projetos):

Pipeline em Python que trata arquivos, filtra registros, organiza nomes, padroniza colunas e insere automaticamente os dados em um banco PostgreSQL na plataforma Neon.

Dashboard em Power BI, que consome esses dados e exibe indicadores estrat√©gicos do GEP, como andamento, situa√ß√£o dos projetos, distribui√ß√£o por √°reas, tempo m√©dio de tramita√ß√£o, entre outros.

Pipeline de Processamento de Projetos + Dashboard Power BI (Indicadores GEP ‚Äì HU-UFPI)
Sobre o Projeto

Este projeto re√∫ne um pipeline de tratamento de dados em Python e um conjunto de dashboards desenvolvidos no Power BI. O objetivo √© organizar, limpar, padronizar e analisar os dados relacionados aos projetos geridos pelo GEP (Gest√£o Estrat√©gica de Projetos) do HU-UFPI, oferecendo uma vis√£o clara e confi√°vel para decis√£o estrat√©gica.

O fluxo completo funciona assim:

Entrada

O usu√°rio insere arquivos CSV brutos na pasta:

csvs/brutos/

Esses arquivos v√™m do HU-UFPI e podem conter inconsist√™ncias, repeti√ß√µes, acentos, colunas mal formatadas etc. - > Sempre s√£o esperados os arquivos relatorio_projetos_historico.csv e relatorio_projetos.csv

Os arquivos s√£o tratados, organizados e filtrados via scripts em Python.

Os dados s√£o enviados automaticamente para um banco PostgreSQL hospedado na Neon.

O Power BI consome esse banco e gera dashboards anal√≠ticos com indicadores essenciais.

1. Pipeline de Processamento em Python
Estrutura Geral

requirements :

pandas
psycopg2-binary (psycopg2)
python-dotenv
DATABASE_URL = variavel local 

O pipeline executa etapas de:

Entrada
Leitura dos arquivos brutos (.csv) contendo informa√ß√µes dos projetos e seus hist√≥ricos.

Tratamento
‚Ä¢ Limpeza de colunas
‚Ä¢ Remo√ß√£o de duplicatas
‚Ä¢ Filtragem de registros inv√°lidos
‚Ä¢ Ajuste de colunas de tempo
‚Ä¢ Cria√ß√£o de estruturas padronizadas
‚Ä¢ Organiza√ß√£o do output em m√∫ltiplas pastas (limpos, sem duplicatas etc.)

Envio para o Banco
Finalizando o processamento, os dados s√£o enviados automaticamente para um banco PostgreSQL/Neon, que √© a fonte principal do Power BI.

Scripts inclu√≠dos

script_limpeza_duplicatas.py ‚Äì remove duplicidades nos registros.

script_limpeza_projetos_inativos.py ‚Äì filtra projetos inativos ou inv√°lidos.

Apipe.py ‚Äì pipeline geral de processamento.

Enviador.py ‚Äì integra√ß√£o com o banco de dados.

update_tempo_trigger.sql ‚Äì trigger SQL para manter a coluna ‚Äútempo‚Äù sempre atualizada conforme altera√ß√µes na coluna ‚Äúduracao‚Äù. (caso um novo banco seja criado esse script deve ser carregado manualmnte, pois √£o faz parte da pipeline)

Estrutura de Pastas
csvs/
 ‚îú‚îÄ‚îÄ brutos/
 ‚îú‚îÄ‚îÄ limpos/
 ‚îî‚îÄ‚îÄ sem_duplicatas/

dashboards/
 ‚îú‚îÄ‚îÄ vers√µes antigas/
 ‚îî‚îÄ‚îÄ vers√µes novas/

*.py
*.sql
README.md

2. Dashboard em Power BI

Ap√≥s o carregamento no PostgreSQL, o Power BI l√™ a base atualizada e monta os pain√©is de indicadores do GEP.

Objetivo do Dashboard

Dar aos gestores do HU-UFPI uma vis√£o r√°pida e precisa sobre o andamento dos projetos institucionais. O painel auxilia tanto o acompanhamento operacional quanto decis√µes estrat√©gicas.

Indicadores dispon√≠veis (ou previstos)

Quantidade total de projetos

Projetos ativos, conclu√≠dos e inativos

Tempo m√©dio de tramita√ß√£o

Distribui√ß√£o por √°rea / categoria

Evolu√ß√£o temporal dos registros

Hist√≥rico de movimenta√ß√£o dos projetos

An√°lises de produtividade

Compara√ß√µes entre per√≠odos

Banco de Dados

O sistema utiliza PostgreSQL (Neon), e parte da l√≥gica do banco √© automatizada com triggers
SQL.
O arquivo update_tempo_trigger.sql garante que qualquer altera√ß√£o na coluna duracao reflita corretamente no campo tempo em segundos.

Como Executar

Coloque seus arquivos brutos em csvs/brutos.

Execute o pipeline (ex.: python Apipe.py).

Os arquivos tratados ser√£o gerados nas respectivas pastas.

O Enviador.py cuidar√° do envio ao PostgreSQL.

Abra o Power BI e atualize o dashboard conectado ao banco.

Observa√ß√µes

Os dashboards possuem vers√µes antiga e nova dentro da pasta dashboards/.

Os arquivos .pbix j√° est√£o configurados para ler do PostgreSQL.

O projeto √© modular, permitindo expans√£o futura para novas regras, novos datasets ou automa√ß√£o cont√≠nua.

3. Artigo 

Este projeto faz parte do estudo ‚ÄúIntegra√ß√£o de ETL em Python e Power BI para Gest√£o Estrat√©gica de Projetos Institucionais no Hospital Universit√°rio da UFPI‚Äù, no qual desenvolvemos uma solu√ß√£o completa de Business Intelligence para monitoramento dos projetos vinculados ao HU-UFPI.

O artigo apresenta o contexto de fragmenta√ß√£o informacional existente no hospital e descreve como a equipe desenvolveu um fluxo end-to-end de dados, composto por:

ETL automatizado em Python, respons√°vel por coletar, limpar, padronizar e consolidar dados provenientes de planilhas institucionais;

Modelagem e armazenamento em um banco de dados relacional (PostgreSQL/Neon);

Dashboards interativos em Power BI, exibindo indicadores como classifica√ß√£o dos projetos, evolu√ß√£o temporal, participa√ß√£o multic√™ntrica, tipos de estudo, andamento processual e produtos previstos.

O estudo demonstra que a solu√ß√£o implementada melhora a governan√ßa da informa√ß√£o, reduz inconsist√™ncias presentes nas planilhas brutas, aumenta a transpar√™ncia e fortalece a tomada de decis√£o baseada em evid√™ncias dentro do HU-UFPI. O pipeline proposto tamb√©m se mostra escal√°vel, replic√°vel e adequado √†s demandas anal√≠ticas de hospitais universit√°rios.